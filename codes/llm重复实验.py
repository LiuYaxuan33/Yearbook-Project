import openai
import pandas as pd
import json
import os
import re
import time
from tqdm import tqdm
import matplotlib.pyplot as plt
import numpy as np
import random
from collections import defaultdict
import matplotlib.pyplot as plt
import seaborn as sns
from dotenv import load_dotenv

load_dotenv()

# âœ… åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆæ–°ç‰ˆæœ¬APIä¿®æ”¹ç‚¹1ï¼‰
client = openai.OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com/v1"  # DeepSeekä¸“å±ç«¯ç‚¹
)

with open("dimensions.json", "r", encoding="utf-8") as f0:
    dimension_all = json.load(f0)

framework = dimension_all[0]
root_words = dimension_all[1]

CUSTOM_CATEGORIES = []

for key, value in framework.items():
    CUSTOM_CATEGORIES.extend(value)

print(CUSTOM_CATEGORIES)

# åˆ†æç»´åº¦

# Prompt æ„å»º
def make_prompt(comment):
    return f"""
You are an expert in psychology and linguistic analysis.  
Given the following student graduation comment:

"{comment}"

Please rate the presence of each of the following dimensions on a scale from 0 to 1 (where 0 means not present at all, 1 means strongly present).  
Output JSON with format: {{'dimension_name': score, ...}}

Dimensions:
{', '.join(CUSTOM_CATEGORIES)}

provide json only, without markdown citations(for example, '```json' or '```') or extra notes
"""

# è°ƒç”¨ DeepSeek Chat API
def analyze_comment(comment):
    try:
        response = client.chat.completions.create(  # æ–°APIè°ƒç”¨æ–¹å¼
            model="deepseek-chat",
            messages=[
                {"role": "user", "content": make_prompt(comment)}
            ],
            temperature=0
        )
        text = response.choices[0].message.content  # æ–°å±æ€§è®¿é—®æ–¹å¼
        text = re.sub(r'^```(?:json)?\s*', '', text)
        text = re.sub(r'\s*```$', '', text)
        return json.loads(text)
    except json.JSONDecodeError:
        print(f"JSON è§£æå¤±è´¥ï¼ŒåŸå§‹å“åº”å†…å®¹: {text}")
        return {dim: 0 for dim in CUSTOM_CATEGORIES}
    except Exception as e:
        print(f"[Error] {e}")
        return {dim: 0 for dim in CUSTOM_CATEGORIES}

# ğŸ”„ å¤„ç†æ‰¹æ¬¡
def process_batch(students, processed_names, batch_size=100, save_path="deepseek_emotion_scores.csv"):
    results = []

    for student in tqdm(students, desc="Processing comments"):
        if student["name"] in processed_names:
            continue

        print(f"ğŸ” Analyzing {student['name']} ({len(processed_names)+1}/{len(students)})")
    
        comment = student["comment"]
        result = analyze_comment(comment)
        result.update({
            "name": student["name"],
            "gender": student.get("gender", ""),
            "year": student.get("year", "")
        })

        results.append(result)

        df = pd.DataFrame([result])
        df.to_csv(save_path, mode="a", index=False, header=not os.path.exists(save_path))

        processed_names.add(student["name"])
        time.sleep(1.2)



# ğŸ“‚ å·²å®Œæˆè®°å½•
processed_names = set()
save_file = "deepseek_emotion_scores.csv"
if os.path.exists(save_file):
    processed = pd.read_csv(save_file)
    processed_names = set(processed["name"].unique())


# ç¨³å®šæ€§æµ‹è¯•å‚æ•°é…ç½®
STABILITY_CONFIG = {
    "num_samples": 100,      # éšæœºæŠ½å–æ ·æœ¬æ•°é‡
    "num_runs": 10,        # æ¯ä¸ªæ ·æœ¬é‡å¤æ¬¡æ•°
    "results_file": "0520_stability_results.csv",  # ç»“æœå­˜å‚¨æ–‡ä»¶
    "samples_file": "0520_stability_samples.json", # æŠ½æ ·è®°å½•æ–‡ä»¶
    "sleep_time": 1.2       # APIè°ƒç”¨é—´éš”
}

def run_stability_test():
    """æ‰§è¡Œç¨³å®šæ€§æµ‹è¯•ä¸»å‡½æ•°"""
    # åŠ è½½æ‰€æœ‰å­¦ç”Ÿæ•°æ®
    with open("all_data_use_labeled.json", "r", encoding="utf-8") as f:
        all_students = json.load(f)
    
    # è·å–æˆ–åˆ›å»ºæŠ½æ ·æ ·æœ¬
    selected_students = _get_samples(all_students)
    
    # åŠ è½½å·²å¤„ç†è®°å½•
    processed = _load_processed_records()
    
    # è®¡ç®—å‰©ä½™ä»»åŠ¡é‡
    total_tasks = _calculate_remaining_tasks(selected_students, processed)
    
    # æ‰§è¡Œæµ‹è¯•ä»»åŠ¡
    with tqdm(total=total_tasks, desc="Stability Test Progress") as pbar:
        for student in selected_students:
            name = student["name"]
            remaining_runs = _get_remaining_runs(name, processed)
            
            for run_id in remaining_runs:
                _process_single_run(student, run_id)
                _update_progress(pbar, name, run_id, processed)
                
                time.sleep(STABILITY_CONFIG["sleep_time"])
    
    # ç»“æœåˆ†æä¸å¯è§†åŒ–
    analyze_stability_results()

def _get_samples(all_students):
    """è·å–æˆ–åˆ›å»ºæŠ½æ ·æ ·æœ¬"""
    if os.path.exists(STABILITY_CONFIG["samples_file"]):
        with open(STABILITY_CONFIG["samples_file"], "r", encoding='utf-8') as f:
            return json.load(f)
    
    selected = random.sample(all_students, STABILITY_CONFIG["num_samples"])
    with open(STABILITY_CONFIG["samples_file"], "w") as f:
        json.dump(selected, f, ensure_ascii=False, indent=2)
    return selected

def _load_processed_records():
    """åŠ è½½å·²å¤„ç†è®°å½•"""
    processed = defaultdict(set)
    if os.path.exists(STABILITY_CONFIG["results_file"]):
        df = pd.read_csv(STABILITY_CONFIG["results_file"])
        for _, row in df.iterrows():
            processed[row["name"]].add(row["run_id"])
    return processed

def _calculate_remaining_tasks(students, processed):
    """è®¡ç®—å‰©ä½™ä»»åŠ¡æ€»æ•°"""
    return sum(
        STABILITY_CONFIG["num_runs"] - len(processed.get(s["name"], set()))
        for s in students
    )

def _get_remaining_runs(name, processed):
    """è·å–éœ€è¦è¿è¡Œçš„å‰©ä½™run_id"""
    completed = processed.get(name, set())
    return [
        run_id for run_id in range(1, STABILITY_CONFIG["num_runs"] + 1)
        if run_id not in completed
    ]

def _process_single_run(student, run_id):
    """å¤„ç†å•ä¸ªè¿è¡Œå®ä¾‹"""
    result = analyze_comment(student["comment"])
    record = {
        "name": student["name"],
        "gender": student.get("gender", ""),
        "year": student.get("year", ""),
        "run_id": run_id,
        **result
    }
    pd.DataFrame([record]).to_csv(
        STABILITY_CONFIG["results_file"],
        mode="a",
        header=not os.path.exists(STABILITY_CONFIG["results_file"]),
        index=False
    )

def _update_progress(pbar, name, run_id, processed):
    """æ›´æ–°è¿›åº¦å’Œè®°å½•"""
    pbar.update(1)
    processed[name].add(run_id)

def analyze_stability_results():
    """åˆ†æç»“æœå¹¶ç”Ÿæˆå¯è§†åŒ–"""
    df = pd.read_csv(STABILITY_CONFIG["results_file"])
    
    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    stats = df.groupby("name")[CUSTOM_CATEGORIES].agg(["mean", "std", "sem"])
    
    # ç»´åº¦ç¨³å®šæ€§åˆ†æ
    plt.figure(figsize=(12, 6))
    sns.boxplot(data=df[CUSTOM_CATEGORIES])
    plt.title("Score Distribution Across All Runs")
    plt.xticks(rotation=45)
    plt.show()
    
    # å„ç»´åº¦å˜å¼‚ç³»æ•°åˆ†æ
    cv = stats.xs("std", axis=1, level=1).mean() / stats.xs("mean", axis=1, level=1).mean()
    cv.plot(kind="bar", title="Coefficient of Variation by Dimension")
    plt.ylabel("CV (std/mean)")
    plt.show()
    
    # æ ·æœ¬ç¨³å®šæ€§çƒ­åŠ›å›¾
    plt.figure(figsize=(15, 8))
    sns.heatmap(
        stats.xs("std", axis=1, level=1).T,
        annot=False,
        cmap="YlGnBu",
        cbar=True
    )
    plt.title("Standard Deviation Heatmap (Columns: Samples, Rows: Dimensions)")
    plt.xticks([], [])
    plt.yticks([], [])
    plt.show()

    heatmap_values = stats.xs("std", axis=1, level=1).T

    heatmap_values.to_csv("heatmap_values.csv")


# åœ¨åŸæœ‰ä»£ç åæ·»åŠ è°ƒç”¨ï¼ˆç¡®ä¿åŸæœ‰æµç¨‹è¢«æ³¨é‡Šï¼‰
# process_batch(students, processed_names, ...)  # æ³¨é‡ŠåŸæœ‰å¤„ç†æµç¨‹
run_stability_test()  # æ‰§è¡Œç¨³å®šæ€§æµ‹è¯•